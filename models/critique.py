"""
Critique Model

Defines the structure for red team critiques generated by adversarial agents.
Critiques challenge blue team outputs across multiple dimensions.
"""

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import List, Optional, ClassVar, Set
import json
import uuid

from agents.utils import DataclassMixin


class ChallengeType(str, Enum):
    """Types of challenges a red team agent can raise."""

    LOGIC = "logic"  # Logical flaws, invalid reasoning, contradictions
    EVIDENCE = "evidence"  # Unsupported claims, missing data, weak proof
    COMPLETENESS = "completeness"  # Missing elements, gaps in coverage
    RISK = "risk"  # Unaddressed risks, failure modes
    COMPLIANCE = "compliance"  # Regulatory/FAR violations, eligibility issues
    COMPETITIVE = "competitive"  # Competitive vulnerabilities, weak positioning
    FEASIBILITY = "feasibility"  # Unrealistic assumptions, execution concerns
    CLARITY = "clarity"  # Ambiguous language, unclear messaging


class Severity(str, Enum):
    """Severity level of a critique."""

    CRITICAL = "critical"  # Must be addressed; blocks approval
    MAJOR = "major"  # Should be addressed; significant impact
    MINOR = "minor"  # Nice to address; limited impact
    OBSERVATION = "observation"  # Informational; no action required


class CritiqueStatus(str, Enum):
    """Status of a critique in the debate workflow."""

    PENDING = "pending"  # Awaiting blue team response
    ADDRESSED = "addressed"  # Blue team has responded
    ACCEPTED = "accepted"  # Critique was accepted, changes made
    REBUTTED = "rebutted"  # Critique was successfully rebutted
    ACKNOWLEDGED = "acknowledged"  # Acknowledged but not fully addressed
    ESCALATED = "escalated"  # Escalated for human review
    WITHDRAWN = "withdrawn"  # Red team withdrew the critique


@dataclass
class Critique(DataclassMixin):
    """
    A structured critique from a red team agent.

    Critiques target specific sections of blue team output and must include
    actionable remediation suggestions.
    """

    id: str = field(default_factory=lambda: str(uuid.uuid4()))

    # Source
    agent: str = ""  # Role of the critiquing agent
    round_number: int = 1

    # Target
    target_document_id: str = ""
    target_section: str = ""
    target_content: str = ""  # The specific content being challenged

    # Classification
    challenge_type: ChallengeType = ChallengeType.LOGIC
    severity: Severity = Severity.MAJOR

    # Content
    title: str = ""  # Brief summary of the critique
    argument: str = ""  # Detailed explanation of the issue
    evidence: str = ""  # Supporting evidence for the critique
    suggested_remedy: str = ""  # Proposed fix

    # Additional context
    related_critiques: List[str] = field(default_factory=list)  # IDs of related critiques
    references: List[str] = field(default_factory=list)  # External references (FAR, etc.)

    # Status tracking
    status: CritiqueStatus = CritiqueStatus.PENDING
    response_id: Optional[str] = None  # ID of the Response addressing this critique

    # Timestamps
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)

    def __post_init__(self):
        """Validate required fields after initialization."""
        if not self.agent:
            raise ValueError("Critique must specify the source agent")
        if not self.argument:
            raise ValueError("Critique must include an argument")
        if not self.suggested_remedy:
            raise ValueError("Critique must include a suggested remedy")

    @property
    def is_blocking(self) -> bool:
        """Check if this critique blocks document approval."""
        return self.severity == Severity.CRITICAL and self.status not in {
            CritiqueStatus.ACCEPTED,
            CritiqueStatus.REBUTTED,
            CritiqueStatus.WITHDRAWN,
        }

    @property
    def is_resolved(self) -> bool:
        """Check if this critique has been resolved."""
        return self.status in {
            CritiqueStatus.ACCEPTED,
            CritiqueStatus.REBUTTED,
            CritiqueStatus.ACKNOWLEDGED,
            CritiqueStatus.WITHDRAWN,
        }

    @property
    def requires_action(self) -> bool:
        """Check if this critique requires action from blue team."""
        return self.status == CritiqueStatus.PENDING and self.severity in {
            Severity.CRITICAL,
            Severity.MAJOR,
        }

    def mark_addressed(self, response_id: str) -> None:
        """Mark the critique as addressed with a response."""
        self.status = CritiqueStatus.ADDRESSED
        self.response_id = response_id
        self.updated_at = datetime.utcnow()

    def accept(self) -> None:
        """Mark the critique as accepted (changes will be made)."""
        self.status = CritiqueStatus.ACCEPTED
        self.updated_at = datetime.utcnow()

    def rebut(self) -> None:
        """Mark the critique as successfully rebutted."""
        self.status = CritiqueStatus.REBUTTED
        self.updated_at = datetime.utcnow()

    def acknowledge(self) -> None:
        """Mark the critique as acknowledged but not fully addressed."""
        self.status = CritiqueStatus.ACKNOWLEDGED
        self.updated_at = datetime.utcnow()

    def escalate(self) -> None:
        """Escalate the critique for human review."""
        self.status = CritiqueStatus.ESCALATED
        self.updated_at = datetime.utcnow()

    def withdraw(self) -> None:
        """Withdraw the critique (red team concedes)."""
        self.status = CritiqueStatus.WITHDRAWN
        self.updated_at = datetime.utcnow()

    @classmethod
    def from_dict(cls, data: dict) -> "Critique":
        # Handle validation by providing defaults for required fields during construction
        critique = cls.__new__(cls)
        critique.id = data.get("id", str(uuid.uuid4()))
        critique.agent = data.get("agent", "Unknown")
        critique.round_number = data.get("round_number", 1)
        critique.target_document_id = data.get("target_document_id", "")
        critique.target_section = data.get("target_section", "")
        critique.target_content = data.get("target_content", "")
        critique.challenge_type = ChallengeType(data.get("challenge_type", "logic"))
        critique.severity = Severity(data.get("severity", "major"))
        critique.title = data.get("title", "")
        critique.argument = data.get("argument", "No argument provided")
        critique.evidence = data.get("evidence", "")
        critique.suggested_remedy = data.get("suggested_remedy", "No remedy provided")
        critique.related_critiques = data.get("related_critiques", [])
        critique.references = data.get("references", [])
        critique.status = CritiqueStatus(data.get("status", "pending"))
        critique.response_id = data.get("response_id")
        critique.created_at = datetime.fromisoformat(data["created_at"]) if data.get("created_at") else datetime.utcnow()
        critique.updated_at = datetime.fromisoformat(data["updated_at"]) if data.get("updated_at") else datetime.utcnow()
        return critique

    def to_json(self) -> str:
        return json.dumps(self.to_dict(), indent=2)

    @classmethod
    def from_json(cls, json_str: str) -> "Critique":
        return cls.from_dict(json.loads(json_str))


@dataclass
class CritiqueSummary(DataclassMixin):
    """
    Summary of critiques for a document or debate round.

    Used for reporting and consensus detection.
    """

    # Include computed properties in to_dict() output
    _include_properties: ClassVar[Set[str]] = {"resolution_rate", "has_blocking_issues"}

    document_id: str = ""
    round_number: Optional[int] = None

    # Counts by status
    total: int = 0
    pending: int = 0
    accepted: int = 0
    rebutted: int = 0
    acknowledged: int = 0
    escalated: int = 0

    # Counts by severity
    critical: int = 0
    major: int = 0
    minor: int = 0
    observations: int = 0

    # Counts by type
    by_type: dict = field(default_factory=dict)

    # Blocking issues
    blocking_critiques: List[str] = field(default_factory=list)  # IDs

    @property
    def has_blocking_issues(self) -> bool:
        """Check if there are any blocking critiques."""
        return len(self.blocking_critiques) > 0

    @property
    def resolution_rate(self) -> float:
        """Calculate the percentage of resolved critiques."""
        if self.total == 0:
            return 100.0
        resolved = self.accepted + self.rebutted + self.acknowledged
        return (resolved / self.total) * 100

    @classmethod
    def from_critiques(
        cls,
        critiques: List[Critique],
        document_id: str = "",
        round_number: Optional[int] = None,
    ) -> "CritiqueSummary":
        """Generate a summary from a list of critiques."""
        summary = cls(document_id=document_id, round_number=round_number)
        summary.total = len(critiques)

        for critique in critiques:
            # Count by status
            if critique.status == CritiqueStatus.PENDING:
                summary.pending += 1
            elif critique.status == CritiqueStatus.ACCEPTED:
                summary.accepted += 1
            elif critique.status == CritiqueStatus.REBUTTED:
                summary.rebutted += 1
            elif critique.status == CritiqueStatus.ACKNOWLEDGED:
                summary.acknowledged += 1
            elif critique.status == CritiqueStatus.ESCALATED:
                summary.escalated += 1

            # Count by severity
            if critique.severity == Severity.CRITICAL:
                summary.critical += 1
            elif critique.severity == Severity.MAJOR:
                summary.major += 1
            elif critique.severity == Severity.MINOR:
                summary.minor += 1
            elif critique.severity == Severity.OBSERVATION:
                summary.observations += 1

            # Count by type
            type_name = critique.challenge_type.value
            summary.by_type[type_name] = summary.by_type.get(type_name, 0) + 1

            # Track blocking critiques
            if critique.is_blocking:
                summary.blocking_critiques.append(critique.id)

        return summary

    def to_json(self) -> str:
        return json.dumps(self.to_dict(), indent=2)
